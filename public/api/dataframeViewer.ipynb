{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e73580f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'predicted_cases'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'predicted_cases'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 315\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m disease_name, df \u001b[38;5;129;01min\u001b[39;00m disease_dataframes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    313\u001b[0m         create_heatmap_for_state(df, disease_name, selectedState)\n\u001b[0;32m--> 315\u001b[0m generate_heatmaps_for_state(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 313\u001b[0m, in \u001b[0;36mgenerate_heatmaps_for_state\u001b[0;34m(selectedState)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_heatmaps_for_state\u001b[39m(selectedState):\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m disease_name, df \u001b[38;5;129;01min\u001b[39;00m disease_dataframes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 313\u001b[0m         create_heatmap_for_state(df, disease_name, selectedState)\n",
      "Cell \u001b[0;32mIn[9], line 295\u001b[0m, in \u001b[0;36mcreate_heatmap_for_state\u001b[0;34m(df, disease_name, state)\u001b[0m\n\u001b[1;32m    290\u001b[0m state_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m state]\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# Create the heatmap\u001b[39;00m\n\u001b[1;32m    293\u001b[0m fig \u001b[38;5;241m=\u001b[39m go\u001b[38;5;241m.\u001b[39mFigure(data\u001b[38;5;241m=\u001b[39mgo\u001b[38;5;241m.\u001b[39mChoropleth(\n\u001b[1;32m    294\u001b[0m     locations\u001b[38;5;241m=\u001b[39mstate_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m],  \u001b[38;5;66;03m# Spatial coordinates (should be just one state)\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m     z\u001b[38;5;241m=\u001b[39mstate_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_cases\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m),  \u001b[38;5;66;03m# Data to be color-coded\u001b[39;00m\n\u001b[1;32m    296\u001b[0m     locationmode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSA-states\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# set of locations match entries in `locations`\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     colorscale\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReds\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    298\u001b[0m     colorbar_title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Cases\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    299\u001b[0m ))\n\u001b[1;32m    301\u001b[0m fig\u001b[38;5;241m.\u001b[39mupdate_layout(\n\u001b[1;32m    302\u001b[0m     title_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisease_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Cases in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    303\u001b[0m     geo_scope\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124musa\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# limit map scope to USA\u001b[39;00m\n\u001b[1;32m    304\u001b[0m )\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# Save the plot as an HTML file\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'predicted_cases'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import calendar\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pyo\n",
    "\n",
    "# # load read data\n",
    "# df_hepatitis = pd.read_csv('Data_Sources/hepatitis.csv')\n",
    "# df_measles = pd.read_csv('Data_Sources/measles.csv')\n",
    "# df_mumps = pd.read_csv('Data_Sources/mumps.csv')\n",
    "# df_pertussis = pd.read_csv('Data_Sources/pertussis.csv')\n",
    "# df_rubella = pd.read_csv('Data_Sources/rubella.csv')\n",
    "# df_smallpox = pd.read_csv('Data_Sources/smallpox.csv')\n",
    "# df_hepatitis\n",
    "\n",
    "# # taking care of data discrepencies \n",
    "# dfs = [df_hepatitis, df_measles, df_mumps, df_pertussis, df_rubella, df_smallpox]\n",
    "\n",
    "# for i, df in enumerate(dfs):\n",
    "#     max_cases = df['cases'].max()  \n",
    "#     dfs[i] = df[df['cases'] != max_cases]  \n",
    "    \n",
    "class DiseasePredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiseasePredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=2, out_features=64)  # Assuming 3 features for simplicity\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)  # Output 1 value: the number of cases\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "# # Define a function to convert DataFrames to tensors\n",
    "# def df_to_tensors(df_features, df_target):\n",
    "#     features_tensor = torch.tensor(df_features.values, dtype=torch.float32)\n",
    "#     target_tensor = torch.tensor(df_target.values, dtype=torch.float32).view(-1, 1)\n",
    "#     return features_tensor, target_tensor\n",
    "\n",
    "# # Loop through each DataFrame\n",
    "# disease_dfs = {\n",
    "#     'Hepatitis': df_hepatitis,\n",
    "#     'Measles': df_measles,\n",
    "#     'Mumps': df_mumps,\n",
    "#     'Pertussis': df_pertussis,\n",
    "#     'Rubella': df_rubella,\n",
    "#     'Smallpox': df_smallpox\n",
    "# }\n",
    "\n",
    "# for disease, df in disease_dfs.items():\n",
    "#     print(f\"\\nProcessing {disease}\")\n",
    "    \n",
    "#     # Assume X and y are defined; you'll need to adapt this part to actually prepare X and y for each df\n",
    "#     X = df[['week', 'incidence_per_capita']]  # Placeholder: replace with actual features\n",
    "#     y = df['cases']\n",
    "    \n",
    "#     # Split into training and validation sets\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "#     # Convert to tensors\n",
    "#     X_train_tensor, y_train_tensor = df_to_tensors(X_train, y_train)\n",
    "#     X_val_tensor, y_val_tensor = df_to_tensors(X_val, y_val)\n",
    "    \n",
    "#     # Initialize model and other components for each disease to avoid knowledge retention\n",
    "#     model = DiseasePredictor()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#     criterion = torch.nn.MSELoss()\n",
    "    \n",
    "#     # Training loop\n",
    "#     epochs = 5\n",
    "#     for epoch in range(epochs):\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(X_train_tensor)\n",
    "#         loss = criterion(outputs, y_train_tensor)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "    \n",
    "#     # Evaluation\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         predictions = model(X_val_tensor)\n",
    "#         val_loss = criterion(predictions, y_val_tensor)\n",
    "#         print(f\"{disease} Validation Loss: {val_loss.item()}\")\n",
    "\n",
    "#     # Optionally, save each model with a disease-specific name\n",
    "#     torch.save(model.state_dict(), f'{disease.lower()}_model.pth')\n",
    "    \n",
    "# def predict_and_create_table(model, X_features, states):\n",
    "#     # Convert features to tensor\n",
    "#     features_tensor = torch.tensor(X_features.values, dtype=torch.float32)\n",
    "    \n",
    "#     # Predict cases\n",
    "#     model.eval()  # Set the model to evaluation mode\n",
    "#     with torch.no_grad():\n",
    "#         predicted_cases_tensor = model(features_tensor)\n",
    "    \n",
    "#     # Convert predictions to numpy array\n",
    "#     predicted_cases = predicted_cases_tensor.numpy().flatten()  # Adjust shape as necessary\n",
    "    \n",
    "#     # Create DataFrame with state and predicted cases\n",
    "#     predicted_df = pd.DataFrame({\n",
    "#         'State': states,\n",
    "#         'Predicted Cases': predicted_cases\n",
    "#     })\n",
    "    \n",
    "#     return predicted_df\n",
    "\n",
    "# # Assuming disease_dfs dictionary is already defined and filled with DataFrames for each disease\n",
    "\n",
    "# for disease, df in disease_dfs.items():\n",
    "#     print(f\"\\nProcessing {disease}\")\n",
    "    \n",
    "#     # Extract state information\n",
    "#     states = df['state']\n",
    "    \n",
    "#     # Prepare features - ensure these match your model's expected input\n",
    "#     X = df[['week', 'incidence_per_capita']]\n",
    "    \n",
    "#     # Initialize model - assuming a single model architecture for all diseases\n",
    "#     model = DiseasePredictor()\n",
    "#     # Load the trained model weights - replace 'your_model_path.pth' with the actual path\n",
    "#     model_path = f'{disease.lower()}_model.pth'\n",
    "#     model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "#     # Predict cases and create table\n",
    "#     predicted_table = predict_and_create_table(model, X, states)\n",
    "    \n",
    "#     # Print the table\n",
    "#     print(f\"{disease} Predicted Cases by State:\")\n",
    "#     print(predicted_table)\n",
    "    \n",
    "#     # # Convert X_train and y_train to PyTorch tensors\n",
    "# # X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "# # y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "\n",
    "# # # If y_train is a series, ensure it's reshaped into a 2D tensor for consistency\n",
    "# # y_train_tensor = y_train_tensor.view(-1, 1)\n",
    "\n",
    "# # epochs = 5  # Example epoch count\n",
    "# # for epoch in range(epochs):\n",
    "# #     optimizer.zero_grad()\n",
    "# #     outputs = model(X_train_tensor)  # Use the tensor version\n",
    "# #     loss = criterion(outputs, y_train_tensor)  # Use the tensor version\n",
    "# #     loss.backward()\n",
    "# #     optimizer.step()\n",
    "# #     print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "# # torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# # X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# # X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# # X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "# # y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "# # y_val_tensor = y_val_tensor.view(-1, 1)\n",
    "\n",
    "# # model.eval()  # Set the model to evaluation mode\n",
    "# # with torch.no_grad():\n",
    "# #     predictions = model(X_val_tensor)  # Use the tensor version\n",
    "# #     val_loss = criterion(predictions, y_val_tensor)  # Use the tensor version\n",
    "# #     print(f\"Validation Loss: {val_loss.item()}\")\n",
    "\n",
    "# model_files = ['hepatitis_model.pth', 'measles_model.pth', 'mumps_model.pth', \n",
    "#                'pertussis_model.pth', 'rubella_model.pth', 'smallpox_model.pth']\n",
    "# models = {}\n",
    "\n",
    "# for file_name in model_files:\n",
    "#     model = DiseasePredictor()\n",
    "#     model.load_state_dict(torch.load(file_name))\n",
    "#     model.eval()\n",
    "#     models[file_name] = model\n",
    "    \n",
    "# def calculate_accuracy(model, X_val_tensor, y_val_tensor):\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(X_val_tensor)\n",
    "#         _, predicted_classes = torch.max(outputs, 1)\n",
    "#         correct_predictions = (predicted_classes == y_val_tensor).sum().item()\n",
    "#         accuracy = correct_predictions / y_val_tensor.size(0)\n",
    "#     return accuracy\n",
    "\n",
    "# datasets = {\n",
    "#     'hepatitis': df_hepatitis,\n",
    "#     'measles': df_measles,\n",
    "#     'mumps': df_mumps,\n",
    "#     'pertussis': df_pertussis,\n",
    "#     'rubella': df_rubella,\n",
    "#     'smallpox': df_smallpox\n",
    "# }\n",
    "\n",
    "# # validation_data = {\n",
    "# #     'hepatitis': (X_val_tensor_hepatitis, y_val_tensor_hepatitis),\n",
    "# #     'measles': (X_val_tensor_measles, y_val_tensor_measles),\n",
    "# #     'mumps': (X_val_tensor_mumps, y_val_tensor_mumps),\n",
    "# #     'pertussis': (X_val_tensor_pertussis, y_val_tensor_pertussis),\n",
    "# #     'rubella': (X_val_tensor_rubella, y_val_tensor_rubella),\n",
    "# #     'smallpox': (X_val_tensor_smallpox, y_val_tensor_smallpox)\n",
    "# # }\n",
    "\n",
    "# validation_tensors = {}\n",
    "\n",
    "model_files = ['/Users/harish/Documents/under-the-weather/public/api/Data_Sources/hepatitis_model.pth', '/Users/harish/Documents/under-the-weather/public/api/Data_Sources/measles_model.pth', '/Users/harish/Documents/under-the-weather/public/api/Data_Sources/mumps_model.pth', \n",
    "               '/Users/harish/Documents/under-the-weather/public/api/Data_Sources/pertussis_model.pth', '/Users/harish/Documents/under-the-weather/public/api/Data_Sources/rubella_model.pth', '/Users/harish/Documents/under-the-weather/public/api/Data_Sources/smallpox_model.pth']\n",
    "diseaseNames = ['hepatitis', 'measles', 'mumps', 'pertussis', 'rubella', 'smallpox']\n",
    "\n",
    "models = {}\n",
    "\n",
    "for file_name, disease_name in zip(model_files, diseaseNames):\n",
    "    model = DiseasePredictor()\n",
    "    model.load_state_dict(torch.load(file_name))\n",
    "    model.eval()\n",
    "    models[disease_name] = model\n",
    "\n",
    "# Function to predict cases for a given disease and set of features\n",
    "def predict_cases(model, X_features):\n",
    "    features_tensor = torch.tensor(X_features.values, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        predicted_cases_tensor = model(features_tensor)\n",
    "    predicted_cases = predicted_cases_tensor.numpy().flatten()\n",
    "    return predicted_cases\n",
    "\n",
    "# Now you can use the loaded models to predict cases for each disease\n",
    "# For example, to predict cases for hepatitis\n",
    "df_hepatitis = pd.read_csv('/Users/harish/Documents/under-the-weather/public/api/Data_Sources/hepatitis.csv')  # Load the hepatitis dataset\n",
    "X_hepatitis = df_hepatitis[['week', 'incidence_per_capita']]  # Extract features\n",
    "predicted_cases_hepatitis = predict_cases(models['hepatitis'], X_hepatitis)\n",
    "df_hepatitis['predicted_cases'] = predicted_cases_hepatitis\n",
    "\n",
    "df_measles = pd.read_csv('/Users/harish/Documents/under-the-weather/public/api/Data_Sources/measles.csv')  # Load the hepatitis dataset\n",
    "X_measles = df_measles[['week', 'incidence_per_capita']]  # Extract features\n",
    "predicted_cases_measles = predict_cases(models['measles'], X_measles)\n",
    "df_measles['predicted_cases'] = predicted_cases_measles\n",
    "\n",
    "df_mumps = pd.read_csv('/Users/harish/Documents/under-the-weather/public/api/Data_Sources/mumps.csv')  # Load the hepatitis dataset\n",
    "X_mumps = df_mumps[['week', 'incidence_per_capita']]  # Extract features\n",
    "predicted_cases_mumps = predict_cases(models['mumps'], X_mumps)\n",
    "df_mumps['predicted_cases'] = predicted_cases_mumps\n",
    "\n",
    "\n",
    "df_pertussis = pd.read_csv('/Users/harish/Documents/under-the-weather/public/api/Data_Sources/pertussis.csv')  # Load the hepatitis dataset\n",
    "X_pertussis = df_mumps[['week', 'incidence_per_capita']]  # Extract features\n",
    "predicted_cases_pertussis = predict_cases(models['pertussis'], X_pertussis)\n",
    "df_mumps['predicted_cases'] = predicted_cases_pertussis\n",
    "\n",
    "df_rubella = pd.read_csv('/Users/harish/Documents/under-the-weather/public/api/Data_Sources/rubella.csv')  # Load the hepatitis dataset\n",
    "X_rubella = df_rubella[['week', 'incidence_per_capita']]  # Extract features\n",
    "predicted_cases_rubella = predict_cases(models['rubella'], X_rubella)\n",
    "df_rubella['predicted_cases'] = predicted_cases_rubella\n",
    "\n",
    "df_smallpox = pd.read_csv('/Users/harish/Documents/under-the-weather/public/api/Data_Sources/smallpox.csv')  # Load the hepatitis dataset\n",
    "X_smallpox = df_smallpox[['week', 'incidence_per_capita']]  # Extract features\n",
    "predicted_cases_smallpox = predict_cases(models['smallpox'], X_smallpox)\n",
    "df_smallpox['predicted_cases'] = predicted_cases_smallpox\n",
    "\n",
    "all_states = [\n",
    "        'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', \n",
    "        'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', \n",
    "        'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', \n",
    "        'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', \n",
    "        'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "disease_dataframes = {\n",
    "    'Hepatitis': df_hepatitis,\n",
    "    'Measles': df_measles,\n",
    "    'Mumps': df_mumps,\n",
    "    'Pertussis': df_pertussis,\n",
    "    'Rubella': df_rubella,\n",
    "    'Smallpox': df_smallpox\n",
    "}\n",
    "\n",
    "# # Ensure all DataFrames have a 'predicted_cases' column; add it with default values if missing\n",
    "# for disease_name, df in disease_dataframes.items():\n",
    "#     if 'predicted_cases' not in df.columns:\n",
    "#         df['predicted_cases'] = 0  # Assign a default value\n",
    "\n",
    "# Function to create a heatmap for a given disease DataFrame\n",
    "def create_heatmap_for_state(df, disease_name, state):\n",
    "    # Filter DataFrame for the specified state\n",
    "    state_df = df[df['state'] == state]\n",
    "    \n",
    "    # Create the heatmap\n",
    "    fig = go.Figure(data=go.Choropleth(\n",
    "        locations=state_df['state'],  # Spatial coordinates (should be just one state)\n",
    "        z=state_df['predicted_cases'].astype(float),  # Data to be color-coded\n",
    "        locationmode='USA-states',  # set of locations match entries in `locations`\n",
    "        colorscale='Reds',\n",
    "        colorbar_title=\"Predicted Cases\",\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'Predicted {disease_name} Cases in {state}',\n",
    "        geo_scope='usa',  # limit map scope to USA\n",
    "    )\n",
    "\n",
    "    # Save the plot as an HTML file\n",
    "    filename = f'heatmap_{disease_name.lower()}_{state.lower()}.html'\n",
    "    pyo.plot(fig, filename=filename)\n",
    "\n",
    "\n",
    "def generate_heatmaps_for_state(selectedState):\n",
    "    for disease_name, df in disease_dataframes.items():\n",
    "        create_heatmap_for_state(df, disease_name, selectedState)\n",
    "        \n",
    "generate_heatmaps_for_state(\"NY\")\n",
    "    \n",
    "# df_hepatitis['year'] = df_hepatitis['week'].apply(lambda x: int(str(x)[:4]))\n",
    "# df_hepatitis['week_of_year'] = df_hepatitis['week'].apply(lambda x: int(str(x)[4:]))\n",
    "\n",
    "# # Use the 'year' and 'week_of_year' as features for now\n",
    "# X = df_hepatitis[['year', 'week_of_year', 'incidence_per_capita']]\n",
    "# y = df_hepatitis['cases']\n",
    "\n",
    "# # Splitting the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialize and train the linear regression model\n",
    "# model = LinearRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Predict on the testing set\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# # Calculate R-squared on the training set\n",
    "# r_squared_train = model.score(X_train, y_train)\n",
    "# print(f\"R-squared on the training set: {r_squared_train}\")\n",
    "\n",
    "# # Calculate R-squared on the testing set\n",
    "# r_squared_test = model.score(X_test, y_test)\n",
    "# print(f\"R-squared on the testing set: {r_squared_test}\")\n",
    "\n",
    "# print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91b5bccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>predicted_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[AL, AK, AZ, AR, CA, CO, CT, DE, FL, GA, HI, I...</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               state  predicted_cases\n",
       "0  [AL, AK, AZ, AR, CA, CO, CT, DE, FL, GA, HI, I...              150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_measles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a1e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
