{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e73580f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'public/api/Data_Sources/hepatitis_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 221\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name, disease_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(model_files, diseaseNames):\n\u001b[1;32m    220\u001b[0m     model \u001b[38;5;241m=\u001b[39m DiseasePredictor()\n\u001b[0;32m--> 221\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(file_name))\n\u001b[1;32m    222\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    223\u001b[0m     models[disease_name] \u001b[38;5;241m=\u001b[39m model\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'public/api/Data_Sources/hepatitis_model.pth'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import calendar\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pyo\n",
    "\n",
    "# # load read data\n",
    "# df_hepatitis = pd.read_csv('Data_Sources/hepatitis.csv')\n",
    "# df_measles = pd.read_csv('Data_Sources/measles.csv')\n",
    "# df_mumps = pd.read_csv('Data_Sources/mumps.csv')\n",
    "# df_pertussis = pd.read_csv('Data_Sources/pertussis.csv')\n",
    "# df_rubella = pd.read_csv('Data_Sources/rubella.csv')\n",
    "# df_smallpox = pd.read_csv('Data_Sources/smallpox.csv')\n",
    "# df_hepatitis\n",
    "\n",
    "# # taking care of data discrepencies \n",
    "# dfs = [df_hepatitis, df_measles, df_mumps, df_pertussis, df_rubella, df_smallpox]\n",
    "\n",
    "# for i, df in enumerate(dfs):\n",
    "#     max_cases = df['cases'].max()  \n",
    "#     dfs[i] = df[df['cases'] != max_cases]  \n",
    "    \n",
    "class DiseasePredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiseasePredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=2, out_features=64)  # Assuming 3 features for simplicity\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)  # Output 1 value: the number of cases\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "# # Define a function to convert DataFrames to tensors\n",
    "# def df_to_tensors(df_features, df_target):\n",
    "#     features_tensor = torch.tensor(df_features.values, dtype=torch.float32)\n",
    "#     target_tensor = torch.tensor(df_target.values, dtype=torch.float32).view(-1, 1)\n",
    "#     return features_tensor, target_tensor\n",
    "\n",
    "# # Loop through each DataFrame\n",
    "# disease_dfs = {\n",
    "#     'Hepatitis': df_hepatitis,\n",
    "#     'Measles': df_measles,\n",
    "#     'Mumps': df_mumps,\n",
    "#     'Pertussis': df_pertussis,\n",
    "#     'Rubella': df_rubella,\n",
    "#     'Smallpox': df_smallpox\n",
    "# }\n",
    "\n",
    "# for disease, df in disease_dfs.items():\n",
    "#     print(f\"\\nProcessing {disease}\")\n",
    "    \n",
    "#     # Assume X and y are defined; you'll need to adapt this part to actually prepare X and y for each df\n",
    "#     X = df[['week', 'incidence_per_capita']]  # Placeholder: replace with actual features\n",
    "#     y = df['cases']\n",
    "    \n",
    "#     # Split into training and validation sets\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "#     # Convert to tensors\n",
    "#     X_train_tensor, y_train_tensor = df_to_tensors(X_train, y_train)\n",
    "#     X_val_tensor, y_val_tensor = df_to_tensors(X_val, y_val)\n",
    "    \n",
    "#     # Initialize model and other components for each disease to avoid knowledge retention\n",
    "#     model = DiseasePredictor()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#     criterion = torch.nn.MSELoss()\n",
    "    \n",
    "#     # Training loop\n",
    "#     epochs = 5\n",
    "#     for epoch in range(epochs):\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(X_train_tensor)\n",
    "#         loss = criterion(outputs, y_train_tensor)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "    \n",
    "#     # Evaluation\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         predictions = model(X_val_tensor)\n",
    "#         val_loss = criterion(predictions, y_val_tensor)\n",
    "#         print(f\"{disease} Validation Loss: {val_loss.item()}\")\n",
    "\n",
    "#     # Optionally, save each model with a disease-specific name\n",
    "#     torch.save(model.state_dict(), f'{disease.lower()}_model.pth')\n",
    "    \n",
    "# def predict_and_create_table(model, X_features, states):\n",
    "#     # Convert features to tensor\n",
    "#     features_tensor = torch.tensor(X_features.values, dtype=torch.float32)\n",
    "    \n",
    "#     # Predict cases\n",
    "#     model.eval()  # Set the model to evaluation mode\n",
    "#     with torch.no_grad():\n",
    "#         predicted_cases_tensor = model(features_tensor)\n",
    "    \n",
    "#     # Convert predictions to numpy array\n",
    "#     predicted_cases = predicted_cases_tensor.numpy().flatten()  # Adjust shape as necessary\n",
    "    \n",
    "#     # Create DataFrame with state and predicted cases\n",
    "#     predicted_df = pd.DataFrame({\n",
    "#         'State': states,\n",
    "#         'Predicted Cases': predicted_cases\n",
    "#     })\n",
    "    \n",
    "#     return predicted_df\n",
    "\n",
    "# # Assuming disease_dfs dictionary is already defined and filled with DataFrames for each disease\n",
    "\n",
    "# for disease, df in disease_dfs.items():\n",
    "#     print(f\"\\nProcessing {disease}\")\n",
    "    \n",
    "#     # Extract state information\n",
    "#     states = df['state']\n",
    "    \n",
    "#     # Prepare features - ensure these match your model's expected input\n",
    "#     X = df[['week', 'incidence_per_capita']]\n",
    "    \n",
    "#     # Initialize model - assuming a single model architecture for all diseases\n",
    "#     model = DiseasePredictor()\n",
    "#     # Load the trained model weights - replace 'your_model_path.pth' with the actual path\n",
    "#     model_path = f'{disease.lower()}_model.pth'\n",
    "#     model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "#     # Predict cases and create table\n",
    "#     predicted_table = predict_and_create_table(model, X, states)\n",
    "    \n",
    "#     # Print the table\n",
    "#     print(f\"{disease} Predicted Cases by State:\")\n",
    "#     print(predicted_table)\n",
    "    \n",
    "#     # # Convert X_train and y_train to PyTorch tensors\n",
    "# # X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "# # y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "\n",
    "# # # If y_train is a series, ensure it's reshaped into a 2D tensor for consistency\n",
    "# # y_train_tensor = y_train_tensor.view(-1, 1)\n",
    "\n",
    "# # epochs = 5  # Example epoch count\n",
    "# # for epoch in range(epochs):\n",
    "# #     optimizer.zero_grad()\n",
    "# #     outputs = model(X_train_tensor)  # Use the tensor version\n",
    "# #     loss = criterion(outputs, y_train_tensor)  # Use the tensor version\n",
    "# #     loss.backward()\n",
    "# #     optimizer.step()\n",
    "# #     print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "# # torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# # X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# # X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# # X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "# # y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "# # y_val_tensor = y_val_tensor.view(-1, 1)\n",
    "\n",
    "# # model.eval()  # Set the model to evaluation mode\n",
    "# # with torch.no_grad():\n",
    "# #     predictions = model(X_val_tensor)  # Use the tensor version\n",
    "# #     val_loss = criterion(predictions, y_val_tensor)  # Use the tensor version\n",
    "# #     print(f\"Validation Loss: {val_loss.item()}\")\n",
    "\n",
    "# model_files = ['hepatitis_model.pth', 'measles_model.pth', 'mumps_model.pth', \n",
    "#                'pertussis_model.pth', 'rubella_model.pth', 'smallpox_model.pth']\n",
    "# models = {}\n",
    "\n",
    "# for file_name in model_files:\n",
    "#     model = DiseasePredictor()\n",
    "#     model.load_state_dict(torch.load(file_name))\n",
    "#     model.eval()\n",
    "#     models[file_name] = model\n",
    "    \n",
    "# def calculate_accuracy(model, X_val_tensor, y_val_tensor):\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(X_val_tensor)\n",
    "#         _, predicted_classes = torch.max(outputs, 1)\n",
    "#         correct_predictions = (predicted_classes == y_val_tensor).sum().item()\n",
    "#         accuracy = correct_predictions / y_val_tensor.size(0)\n",
    "#     return accuracy\n",
    "\n",
    "# datasets = {\n",
    "#     'hepatitis': df_hepatitis,\n",
    "#     'measles': df_measles,\n",
    "#     'mumps': df_mumps,\n",
    "#     'pertussis': df_pertussis,\n",
    "#     'rubella': df_rubella,\n",
    "#     'smallpox': df_smallpox\n",
    "# }\n",
    "\n",
    "# # validation_data = {\n",
    "# #     'hepatitis': (X_val_tensor_hepatitis, y_val_tensor_hepatitis),\n",
    "# #     'measles': (X_val_tensor_measles, y_val_tensor_measles),\n",
    "# #     'mumps': (X_val_tensor_mumps, y_val_tensor_mumps),\n",
    "# #     'pertussis': (X_val_tensor_pertussis, y_val_tensor_pertussis),\n",
    "# #     'rubella': (X_val_tensor_rubella, y_val_tensor_rubella),\n",
    "# #     'smallpox': (X_val_tensor_smallpox, y_val_tensor_smallpox)\n",
    "# # }\n",
    "\n",
    "# validation_tensors = {}\n",
    "\n",
    "model_files = ['public/api/Data_Sources/hepatitis_model.pth', 'public/api/Data_Sources/measles_model.pth', 'public/api/Data_Sources/mumps_model.pth', \n",
    "               'public/api/Data_Sources/pertussis_model.pth', 'public/api/Data_Sources/rubella_model.pth', 'public/api/Data_Sources/smallpox_model.pth']\n",
    "diseaseNames = ['hepatitis', 'measles', 'mumps', 'pertussis', 'rubella', 'smallpox']\n",
    "\n",
    "models = {}\n",
    "\n",
    "for file_name, disease_name in zip(model_files, diseaseNames):\n",
    "    model = DiseasePredictor()\n",
    "    model.load_state_dict(torch.load(file_name))\n",
    "    model.eval()\n",
    "    models[disease_name] = model\n",
    "\n",
    "# Function to predict cases for a given disease and set of features\n",
    "def predict_cases(model, X_features):\n",
    "    features_tensor = torch.tensor(X_features.values, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        predicted_cases_tensor = model(features_tensor)\n",
    "    predicted_cases = predicted_cases_tensor.numpy().flatten()\n",
    "    return predicted_cases\n",
    "\n",
    "# Now you can use the loaded models to predict cases for each disease\n",
    "# For example, to predict cases for hepatitis\n",
    "df_hepatitis = pd.read_csv('public/api/Data_Sources/hepatitis.csv')  # Load the hepatitis dataset\n",
    "X_hepatitis = df_hepatitis[['week', 'incidence_per_capita']]  # Extract features\n",
    "predicted_cases_hepatitis = predict_cases(models['hepatitis'], X_hepatitis)\n",
    "df_hepatitis['predicted_cases'] = predicted_cases_hepatitis\n",
    "\n",
    "df_measles = pd.read_csv('public/api/Data_Sources/measles.csv')  # Load the hepatitis dataset\n",
    "X_measles = df_measles[['week', 'incidence_per_capita']]  # Extract features\n",
    "predicted_cases_measles = predict_cases(models['measles'], X_measles)\n",
    "df_measles['predicted_cases'] = predicted_cases_measles\n",
    "\n",
    "df_mumps = pd.read_csv('public/api/Data_Sources/mumps.csv')  # Load the hepatitis dataset\n",
    "X_mumps = df_mumps[['week', 'incidence_per_capita']]  # Extract features\n",
    "predicted_cases_mumps = predict_cases(models['mumps'], X_mumps)\n",
    "df_mumps['predicted_cases'] = predicted_cases_mumps\n",
    "\n",
    "\n",
    "df_pertussis = pd.read_csv('public/api/Data_Sources/pertussis.csv')  # Load the hepatitis dataset\n",
    "X_pertussis = df_mumps[['week', 'incidence_per_capita']]  # Extract features\n",
    "predicted_cases_pertussis = predict_cases(models['pertussis'], X_pertussis)\n",
    "df_mumps['predicted_cases'] = predicted_cases_pertussis\n",
    "\n",
    "df_rubella = pd.read_csv('public/api/Data_Sources/rubella.csv')  # Load the hepatitis dataset\n",
    "X_rubella = df_rubella[['week', 'incidence_per_capita']]  # Extract features\n",
    "predicted_cases_rubella = predict_cases(models['rubella'], X_rubella)\n",
    "df_rubella['predicted_cases'] = predicted_cases_rubella\n",
    "\n",
    "df_smallpox = pd.read_csv('public/api/Data_Sources/smallpox.csv')  # Load the hepatitis dataset\n",
    "X_smallpox = df_smallpox[['week', 'incidence_per_capita']]  # Extract features\n",
    "predicted_cases_smallpox = predict_cases(models['smallpox'], X_smallpox)\n",
    "df_smallpox['predicted_cases'] = predicted_cases_smallpox\n",
    "\n",
    "all_states = [\n",
    "        'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', \n",
    "        'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', \n",
    "        'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', \n",
    "        'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', \n",
    "        'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "df_hepatitis = pd.DataFrame({'state': ['PA'], 'predicted_cases': [100]})\n",
    "df_measles = pd.DataFrame({'state': [all_states], 'predicted_cases': [150]})\n",
    "df_mumps = pd.DataFrame({'state': [all_states], 'predicted_cases': [20]})\n",
    "df_pertussis = pd.DataFrame({'state': [all_states], 'predicted_cases': [250]})\n",
    "df_rubella = pd.DataFrame({'state': [all_states], 'predicted_cases': [300]})\n",
    "df_smallpox = pd.DataFrame({'state': [all_states], 'predicted_cases': [350]})\n",
    "\n",
    "disease_dataframes = {\n",
    "    'Hepatitis': df_hepatitis,\n",
    "    'Measles': df_measles,\n",
    "    'Mumps': df_mumps,\n",
    "    'Pertussis': df_pertussis,\n",
    "    'Rubella': df_rubella,\n",
    "    'Smallpox': df_smallpox\n",
    "}\n",
    "\n",
    "# # Ensure all DataFrames have a 'predicted_cases' column; add it with default values if missing\n",
    "# for disease_name, df in disease_dataframes.items():\n",
    "#     if 'predicted_cases' not in df.columns:\n",
    "#         df['predicted_cases'] = 0  # Assign a default value\n",
    "\n",
    "# Function to create a heatmap for a given disease DataFrame\n",
    "def create_heatmap_for_state(df, disease_name, state):\n",
    "    # Filter DataFrame for the specified state\n",
    "    state_df = df[df['state'] == state]\n",
    "    \n",
    "    # Create the heatmap\n",
    "    fig = go.Figure(data=go.Choropleth(\n",
    "        locations=state_df['state'],  # Spatial coordinates (should be just one state)\n",
    "        z=state_df['predicted_cases'].astype(float),  # Data to be color-coded\n",
    "        locationmode='USA-states',  # set of locations match entries in `locations`\n",
    "        colorscale='Reds',\n",
    "        colorbar_title=\"Predicted Cases\",\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'Predicted {disease_name} Cases in {state}',\n",
    "        geo_scope='usa',  # limit map scope to USA\n",
    "    )\n",
    "\n",
    "    # Save the plot as an HTML file\n",
    "    filename = f'heatmap_{disease_name.lower()}_{state.lower()}.html'\n",
    "    pyo.plot(fig, filename=filename)\n",
    "\n",
    "\n",
    "def generate_heatmaps_for_state(selectedState):\n",
    "    for disease_name, df in disease_dataframes.items():\n",
    "        create_heatmap_for_state(df, disease_name, selectedState)\n",
    "        \n",
    "generate_heatmaps_for_state(\"NY\")\n",
    "    \n",
    "# df_hepatitis['year'] = df_hepatitis['week'].apply(lambda x: int(str(x)[:4]))\n",
    "# df_hepatitis['week_of_year'] = df_hepatitis['week'].apply(lambda x: int(str(x)[4:]))\n",
    "\n",
    "# # Use the 'year' and 'week_of_year' as features for now\n",
    "# X = df_hepatitis[['year', 'week_of_year', 'incidence_per_capita']]\n",
    "# y = df_hepatitis['cases']\n",
    "\n",
    "# # Splitting the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialize and train the linear regression model\n",
    "# model = LinearRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Predict on the testing set\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# # Calculate R-squared on the training set\n",
    "# r_squared_train = model.score(X_train, y_train)\n",
    "# print(f\"R-squared on the training set: {r_squared_train}\")\n",
    "\n",
    "# # Calculate R-squared on the testing set\n",
    "# r_squared_test = model.score(X_test, y_test)\n",
    "# print(f\"R-squared on the testing set: {r_squared_test}\")\n",
    "\n",
    "# print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b5bccb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
