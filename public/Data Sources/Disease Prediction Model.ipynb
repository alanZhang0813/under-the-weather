{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5862bf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\aarav\\anaconda3\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\aarav\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\aarav\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\aarav\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\aarav\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aarav\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\aarav\\anaconda3\\lib\\site-packages (from torch) (2023.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aarav\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\aarav\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "53cb4cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in c:\\users\\aarav\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\aarav\\anaconda3\\lib\\site-packages (from plotly) (8.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c93c5fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import calendar\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0dc4b18b93398e6",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>state</th>\n",
       "      <th>state_name</th>\n",
       "      <th>disease</th>\n",
       "      <th>cases</th>\n",
       "      <th>incidence_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196601</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>HEPATITIS A</td>\n",
       "      <td>5</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>196601</td>\n",
       "      <td>AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>HEPATITIS A</td>\n",
       "      <td>11</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196601</td>\n",
       "      <td>AZ</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>HEPATITIS A</td>\n",
       "      <td>6</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196601</td>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>HEPATITIS A</td>\n",
       "      <td>89</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196601</td>\n",
       "      <td>CO</td>\n",
       "      <td>COLORADO</td>\n",
       "      <td>HEPATITIS A</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90834</th>\n",
       "      <td>201152</td>\n",
       "      <td>VT</td>\n",
       "      <td>VERMONT</td>\n",
       "      <td>HEPATITIS A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90835</th>\n",
       "      <td>201152</td>\n",
       "      <td>WA</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>HEPATITIS A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90836</th>\n",
       "      <td>201152</td>\n",
       "      <td>WI</td>\n",
       "      <td>WISCONSIN</td>\n",
       "      <td>HEPATITIS A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90837</th>\n",
       "      <td>201152</td>\n",
       "      <td>WV</td>\n",
       "      <td>WEST VIRGINIA</td>\n",
       "      <td>HEPATITIS A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90838</th>\n",
       "      <td>201152</td>\n",
       "      <td>WY</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>HEPATITIS A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90839 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         week state     state_name      disease  cases  incidence_per_capita\n",
       "0      196601    AL        ALABAMA  HEPATITIS A      5                  0.14\n",
       "1      196601    AR       ARKANSAS  HEPATITIS A     11                  0.58\n",
       "2      196601    AZ        ARIZONA  HEPATITIS A      6                  0.37\n",
       "3      196601    CA     CALIFORNIA  HEPATITIS A     89                  0.47\n",
       "4      196601    CO       COLORADO  HEPATITIS A      1                  0.05\n",
       "...       ...   ...            ...          ...    ...                   ...\n",
       "90834  201152    VT        VERMONT  HEPATITIS A      0                  0.00\n",
       "90835  201152    WA     WASHINGTON  HEPATITIS A      0                  0.00\n",
       "90836  201152    WI      WISCONSIN  HEPATITIS A      0                  0.00\n",
       "90837  201152    WV  WEST VIRGINIA  HEPATITIS A      0                  0.00\n",
       "90838  201152    WY        WYOMING  HEPATITIS A      0                  0.00\n",
       "\n",
       "[90839 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load read data\n",
    "df_hepatitis = pd.read_csv('hepatitis.csv')\n",
    "df_measles = pd.read_csv('measles.csv')\n",
    "df_mumps = pd.read_csv('mumps.csv')\n",
    "df_pertussis = pd.read_csv('pertussis.csv')\n",
    "df_rubella = pd.read_csv('rubella.csv')\n",
    "df_smallpox = pd.read_csv('smallpox.csv')\n",
    "df_hepatitis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f36cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking care of data discrepencies \n",
    "dfs = [df_hepatitis, df_measles, df_mumps, df_pertussis, df_rubella, df_smallpox]\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    max_cases = df['cases'].max()  \n",
    "    dfs[i] = df[df['cases'] != max_cases]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acfda574",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiseasePredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiseasePredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=2, out_features=64)  # Assuming 3 features for simplicity\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)  # Output 1 value: the number of cases\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "422bce0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Hepatitis\n",
      "Hepatitis Validation Loss: 42110420.0\n",
      "\n",
      "Processing Measles\n",
      "Measles Validation Loss: 25350924.0\n",
      "\n",
      "Processing Mumps\n",
      "Mumps Validation Loss: 5101577.0\n",
      "\n",
      "Processing Pertussis\n",
      "Pertussis Validation Loss: 126145.40625\n",
      "\n",
      "Processing Rubella\n",
      "Rubella Validation Loss: 76890.1328125\n",
      "\n",
      "Processing Smallpox\n",
      "Smallpox Validation Loss: 27919722.0\n"
     ]
    }
   ],
   "source": [
    "# Define a function to convert DataFrames to tensors\n",
    "def df_to_tensors(df_features, df_target):\n",
    "    features_tensor = torch.tensor(df_features.values, dtype=torch.float32)\n",
    "    target_tensor = torch.tensor(df_target.values, dtype=torch.float32).view(-1, 1)\n",
    "    return features_tensor, target_tensor\n",
    "\n",
    "# Loop through each DataFrame\n",
    "disease_dfs = {\n",
    "    'Hepatitis': df_hepatitis,\n",
    "    'Measles': df_measles,\n",
    "    'Mumps': df_mumps,\n",
    "    'Pertussis': df_pertussis,\n",
    "    'Rubella': df_rubella,\n",
    "    'Smallpox': df_smallpox\n",
    "}\n",
    "\n",
    "for disease, df in disease_dfs.items():\n",
    "    print(f\"\\nProcessing {disease}\")\n",
    "    \n",
    "    # Assume X and y are defined; you'll need to adapt this part to actually prepare X and y for each df\n",
    "    X = df[['week', 'incidence_per_capita']]  # Placeholder: replace with actual features\n",
    "    y = df['cases']\n",
    "    \n",
    "    # Split into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_train_tensor, y_train_tensor = df_to_tensors(X_train, y_train)\n",
    "    X_val_tensor, y_val_tensor = df_to_tensors(X_val, y_val)\n",
    "    \n",
    "    # Initialize model and other components for each disease to avoid knowledge retention\n",
    "    model = DiseasePredictor()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    # Training loop\n",
    "    epochs = 5\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_val_tensor)\n",
    "        val_loss = criterion(predictions, y_val_tensor)\n",
    "        print(f\"{disease} Validation Loss: {val_loss.item()}\")\n",
    "\n",
    "    # Optionally, save each model with a disease-specific name\n",
    "    torch.save(model.state_dict(), f'{disease.lower()}_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8e5f5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Hepatitis\n",
      "Hepatitis Predicted Cases by State:\n",
      "      State  Predicted Cases\n",
      "0        AL      6426.687012\n",
      "1        AR      6426.750488\n",
      "2        AZ      6426.720703\n",
      "3        CA      6426.735352\n",
      "4        CO      6426.675293\n",
      "...     ...              ...\n",
      "90834    VT      6575.432129\n",
      "90835    WA      6575.432129\n",
      "90836    WI      6575.432129\n",
      "90837    WV      6575.432129\n",
      "90838    WY      6575.432129\n",
      "\n",
      "[90839 rows x 2 columns]\n",
      "\n",
      "Processing Measles\n",
      "Measles Predicted Cases by State:\n",
      "       State  Predicted Cases\n",
      "0         AL      5062.830566\n",
      "1         AR      5062.849121\n",
      "2         AZ      5062.762207\n",
      "3         CA      5062.740234\n",
      "4         CO      5063.017090\n",
      "...      ...              ...\n",
      "145162    NV      5258.346191\n",
      "145163    NY      5258.346191\n",
      "145164    OH      5258.346191\n",
      "145165    TX      5258.346191\n",
      "145166    UT      5258.346191\n",
      "\n",
      "[145167 rows x 2 columns]\n",
      "\n",
      "Processing Mumps\n",
      "Mumps Predicted Cases by State:\n",
      "      State  Predicted Cases\n",
      "0        AK      2252.207764\n",
      "1        AL      2252.053467\n",
      "2        AZ      2252.053467\n",
      "3        CA      2252.071533\n",
      "4        DC      2251.936768\n",
      "...     ...              ...\n",
      "69749    TN      2291.410400\n",
      "69750    TX      2291.410400\n",
      "69751    UT      2291.411377\n",
      "69752    VA      2291.411377\n",
      "69753    WI      2291.411377\n",
      "\n",
      "[69754 rows x 2 columns]\n",
      "\n",
      "Processing Pertussis\n",
      "Pertussis Predicted Cases by State:\n",
      "       State  Predicted Cases\n",
      "0         AL      -322.621124\n",
      "1         AR      -322.631866\n",
      "2         AZ      -322.718781\n",
      "3         CA      -322.775421\n",
      "4         CO      -322.625031\n",
      "...      ...              ...\n",
      "109067    VT      -334.861359\n",
      "109068    WA      -334.839874\n",
      "109069    WI      -334.832550\n",
      "109070    WV      -334.857941\n",
      "109071    WY      -334.835968\n",
      "\n",
      "[109072 rows x 2 columns]\n",
      "\n",
      "Processing Rubella\n",
      "Rubella Predicted Cases by State:\n",
      "      State  Predicted Cases\n",
      "0        AL      -265.887054\n",
      "1        AZ      -265.945648\n",
      "2        CA      -265.880707\n",
      "3        CT      -265.893890\n",
      "4        HI      -265.882172\n",
      "...     ...              ...\n",
      "53200    DE      -270.816498\n",
      "53201    FL      -270.816498\n",
      "53202    MI      -270.816498\n",
      "53203    TX      -270.816498\n",
      "53204    UT      -270.816498\n",
      "\n",
      "[53205 rows x 2 columns]\n",
      "\n",
      "Processing Smallpox\n",
      "Smallpox Predicted Cases by State:\n",
      "      State  Predicted Cases\n",
      "0        AL     -5251.699707\n",
      "1        AR     -5251.690918\n",
      "2        AZ     -5251.699707\n",
      "3        CA     -5251.691895\n",
      "4        CO     -5251.622070\n",
      "...     ...              ...\n",
      "50911    NM     -5317.752441\n",
      "50912    NV     -5317.769531\n",
      "50913    MT     -5318.104980\n",
      "50914    SD     -5318.239746\n",
      "50915    IA     -5318.407715\n",
      "\n",
      "[50916 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def predict_and_create_table(model, X_features, states):\n",
    "    # Convert features to tensor\n",
    "    features_tensor = torch.tensor(X_features.values, dtype=torch.float32)\n",
    "    \n",
    "    # Predict cases\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        predicted_cases_tensor = model(features_tensor)\n",
    "    \n",
    "    # Convert predictions to numpy array\n",
    "    predicted_cases = predicted_cases_tensor.numpy().flatten()  # Adjust shape as necessary\n",
    "    \n",
    "    # Create DataFrame with state and predicted cases\n",
    "    predicted_df = pd.DataFrame({\n",
    "        'State': states,\n",
    "        'Predicted Cases': predicted_cases\n",
    "    })\n",
    "    \n",
    "    return predicted_df\n",
    "\n",
    "# Assuming disease_dfs dictionary is already defined and filled with DataFrames for each disease\n",
    "\n",
    "for disease, df in disease_dfs.items():\n",
    "    print(f\"\\nProcessing {disease}\")\n",
    "    \n",
    "    # Extract state information\n",
    "    states = df['state']\n",
    "    \n",
    "    # Prepare features - ensure these match your model's expected input\n",
    "    X = df[['week', 'incidence_per_capita']]\n",
    "    \n",
    "    # Initialize model - assuming a single model architecture for all diseases\n",
    "    model = DiseasePredictor()\n",
    "    # Load the trained model weights - replace 'your_model_path.pth' with the actual path\n",
    "    model_path = f'{disease.lower()}_model.pth'\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    # Predict cases and create table\n",
    "    predicted_table = predict_and_create_table(model, X, states)\n",
    "    \n",
    "    # Print the table\n",
    "    print(f\"{disease} Predicted Cases by State:\")\n",
    "    print(predicted_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e95d5917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert X_train and y_train to PyTorch tensors\n",
    "# X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "# y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "\n",
    "# # If y_train is a series, ensure it's reshaped into a 2D tensor for consistency\n",
    "# y_train_tensor = y_train_tensor.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "3feb1636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 5  # Example epoch count\n",
    "# for epoch in range(epochs):\n",
    "#     optimizer.zero_grad()\n",
    "#     outputs = model(X_train_tensor)  # Use the tensor version\n",
    "#     loss = criterion(outputs, y_train_tensor)  # Use the tensor version\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b54a3da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e4a4b30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "17b1113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "# y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "# y_val_tensor = y_val_tensor.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "69974b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5908156.5\n"
     ]
    }
   ],
   "source": [
    "# model.eval()  # Set the model to evaluation mode\n",
    "# with torch.no_grad():\n",
    "#     predictions = model(X_val_tensor)  # Use the tensor version\n",
    "#     val_loss = criterion(predictions, y_val_tensor)  # Use the tensor version\n",
    "#     print(f\"Validation Loss: {val_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "59ab6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_files = ['hepatitis_model.pth', 'measles_model.pth', 'mumps_model.pth', \n",
    "               'pertussis_model.pth', 'rubella_model.pth', 'smallpox_model.pth']\n",
    "models = {}\n",
    "\n",
    "for file_name in model_files:\n",
    "    model = DiseasePredictor()\n",
    "    model.load_state_dict(torch.load(file_name))\n",
    "    model.eval()\n",
    "    models[file_name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9ae6020f65f6f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, X_val_tensor, y_val_tensor):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_val_tensor)\n",
    "        _, predicted_classes = torch.max(outputs, 1)\n",
    "        correct_predictions = (predicted_classes == y_val_tensor).sum().item()\n",
    "        accuracy = correct_predictions / y_val_tensor.size(0)\n",
    "    return accuracy\n",
    "\n",
    "datasets = {\n",
    "    'hepatitis': df_hepatitis,\n",
    "    'measles': df_measles,\n",
    "    'mumps': df_mumps,\n",
    "    'pertussis': df_pertussis,\n",
    "    'rubella': df_rubella,\n",
    "    'smallpox': df_smallpox\n",
    "}\n",
    "\n",
    "# validation_data = {\n",
    "#     'hepatitis': (X_val_tensor_hepatitis, y_val_tensor_hepatitis),\n",
    "#     'measles': (X_val_tensor_measles, y_val_tensor_measles),\n",
    "#     'mumps': (X_val_tensor_mumps, y_val_tensor_mumps),\n",
    "#     'pertussis': (X_val_tensor_pertussis, y_val_tensor_pertussis),\n",
    "#     'rubella': (X_val_tensor_rubella, y_val_tensor_rubella),\n",
    "#     'smallpox': (X_val_tensor_smallpox, y_val_tensor_smallpox)\n",
    "# }\n",
    "\n",
    "validation_tensors = {}\n",
    "\n",
    "for disease, df in datasets.items():\n",
    "    X = df['incidence_per_capita']  # Your actual feature columns\n",
    "    y = df['cases']  # Or whatever your target column is\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Convert X_val, y_val to tensors\n",
    "    X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1)  # Adjust dtype if classification\n",
    "    \n",
    "    validation_tensors[disease] = (X_val_tensor, y_val_tensor)\n",
    "    \n",
    "for pth in model_files:\n",
    "    disease_name = pth.split(\"_\")[0]  # Assuming naming convention holds\n",
    "    model = models[pth]\n",
    "    \n",
    "    X_val_tensor, y_val_tensor = validation_tensors[disease_name]  # Get the correct validation tensors\n",
    "    \n",
    "    # Assuming calculate_accuracy function definition remains the same\n",
    "    accuracy = calculate_accuracy(model, X_val_tensor, y_val_tensor)\n",
    "    print(f\"{disease_name.capitalize()} Model Accuracy: {accuracy}\")\n",
    "\n",
    "# # Printing each model's accuracy\n",
    "# for pth in model_files:\n",
    "#     disease_name = pth.split(\"_\")[0].capitalize()\n",
    "#     model = models[pth]\n",
    "#     X_val_disease, y_val_disease = validation_data[disease_name]\n",
    "#     accuracy = calculate_accuracy(model, X_val_disease, y_val_disease)\n",
    "#     print(f\"{disease_name} Model Accuracy: {accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "32fc7a58",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[206], line 65\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Generate and save a heatmap for each disease\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m disease_name, df \u001b[38;5;129;01min\u001b[39;00m disease_dataframes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 65\u001b[0m     create_heatmap(df, disease_name)\n",
      "Cell \u001b[1;32mIn[206], line 41\u001b[0m, in \u001b[0;36mcreate_heatmap\u001b[1;34m(df, disease_name)\u001b[0m\n\u001b[0;32m     32\u001b[0m all_states \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAK\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAZ\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGA\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mME\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMD\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTX\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWV\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWY\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     38\u001b[0m ]\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Add missing states with default predicted_cases value\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m missing_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(all_states) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     42\u001b[0m missing_data \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m: state, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_cases\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m} \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m missing_states]\n\u001b[0;32m     43\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, pd\u001b[38;5;241m.\u001b[39mDataFrame(missing_data)], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "all_states = [\n",
    "        'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', \n",
    "        'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', \n",
    "        'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', \n",
    "        'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', \n",
    "        'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "df_hepatitis = pd.DataFrame({'state': ['PA'], 'predicted_cases': [100]})\n",
    "df_measles = pd.DataFrame({'state': [all_states], 'predicted_cases': [150]})\n",
    "df_mumps = pd.DataFrame({'state': [all_states], 'predicted_cases': [20]})\n",
    "df_pertussis = pd.DataFrame({'state': [all_states], 'predicted_cases': [250]})\n",
    "df_rubella = pd.DataFrame({'state': [all_states], 'predicted_cases': [300]})\n",
    "df_smallpox = pd.DataFrame({'state': [all_states], 'predicted_cases': [350]})\n",
    "\n",
    "disease_dataframes = {\n",
    "    'Hepatitis': df_hepatitis,\n",
    "    'Measles': df_measles,\n",
    "    'Mumps': df_mumps,\n",
    "    'Pertussis': df_pertussis,\n",
    "    'Rubella': df_rubella,\n",
    "    'Smallpox': df_smallpox\n",
    "}\n",
    "\n",
    "# Ensure all DataFrames have a 'predicted_cases' column; add it with default values if missing\n",
    "for disease_name, df in disease_dataframes.items():\n",
    "    if 'predicted_cases' not in df.columns:\n",
    "        df['predicted_cases'] = 0  # Assign a default value\n",
    "\n",
    "# Function to create a heatmap for a given disease DataFrame\n",
    "def create_heatmap(df, disease_name):\n",
    "    # List of all US state abbreviations\n",
    "    all_states = [\n",
    "        'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', \n",
    "        'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', \n",
    "        'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', \n",
    "        'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', \n",
    "        'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY'\n",
    "    ]\n",
    "    \n",
    "    # Add missing states with default predicted_cases value\n",
    "    missing_states = set(all_states) - set(df['state'])\n",
    "    missing_data = [{'state': state, 'predicted_cases': 0} for state in missing_states]\n",
    "    df = pd.concat([df, pd.DataFrame(missing_data)], ignore_index=True)\n",
    "    \n",
    "    # Create the heatmap\n",
    "    fig = go.Figure(data=go.Choropleth(\n",
    "        locations=df['state'],  # Spatial coordinates\n",
    "        z=df['predicted_cases'].astype(float),  # Data to be color-coded\n",
    "        locationmode='USA-states',  # set of locations match entries in `locations`\n",
    "        colorscale='Reds',\n",
    "        colorbar_title=\"Predicted Cases\",\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'Predicted {disease_name} Cases by State',\n",
    "        geo_scope='usa',  # limit map scope to USA\n",
    "    )\n",
    "\n",
    "    # Save the plot as an HTML file\n",
    "    filename = f'heatmap_{disease_name.lower()}.html'\n",
    "    pyo.plot(fig, filename=filename)\n",
    "\n",
    "# Generate and save a heatmap for each disease\n",
    "for disease_name, df in disease_dataframes.items():\n",
    "    create_heatmap(df, disease_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9da6544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hepatitis['year'] = df_hepatitis['week'].apply(lambda x: int(str(x)[:4]))\n",
    "# df_hepatitis['week_of_year'] = df_hepatitis['week'].apply(lambda x: int(str(x)[4:]))\n",
    "\n",
    "# # Use the 'year' and 'week_of_year' as features for now\n",
    "# X = df_hepatitis[['year', 'week_of_year', 'incidence_per_capita']]\n",
    "# y = df_hepatitis['cases']\n",
    "\n",
    "# # Splitting the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01c70ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared on the training set: 0.1599361581139458\n",
      "R-squared on the testing set: 0.14466848839838797\n",
      "RMSE: 20.72902526140426\n"
     ]
    }
   ],
   "source": [
    "# # Initialize and train the linear regression model\n",
    "# model = LinearRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Predict on the testing set\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# # Calculate R-squared on the training set\n",
    "# r_squared_train = model.score(X_train, y_train)\n",
    "# print(f\"R-squared on the training set: {r_squared_train}\")\n",
    "\n",
    "# # Calculate R-squared on the testing set\n",
    "# r_squared_test = model.score(X_test, y_test)\n",
    "# print(f\"R-squared on the testing set: {r_squared_test}\")\n",
    "\n",
    "# print(f\"RMSE: {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
